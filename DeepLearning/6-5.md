# 6-5. 역전파와 기타 미분 알고리즘들

* 순전파(forward propagation): 정보가 신경망을 따라 앞으로 흘러가며, 초기 정보에서 각 은닉 단위들로 전파되어서 출력층에 도달하는 과정

* 역전파(back-propagation): 순전파의 반복으로 얻은 비용에서 나온 정보로 신경망을 따라 거꾸로 기울기를 계산
    * 역전파는 기울기를 계산하는 방법일 뿐 학습 알고리즘 자체는 아님

## 계산 그래프

![계산 그래프](https://www.oreilly.com/library/view/python-machine-learning/9781787125933/graphics/B07030_14_02.jpg)

## 미분의 연쇄법칙

![chain rule](https://cdn-images-1.medium.com/max/1600/1*XGeycQtBQLLBzMjMRqCFjQ.png)

## 연쇄법칙을 재귀적으로 적용해서 역전파 구하기

* 연쇄법칙 덕분에, 스칼라의 기울기를 구하는 대수식을 유도하는 것 자체는 어려운 일이 아니다. 그러나 그러한 수식을 실제로 컴퓨터에서 평가할 때에는 고려해야 할 사항들이 더 있다.
    * 기울기에 대한 전체 수식 안에 다수의 부분식이 여러 번 되풀이될 수 있는데 이를 저장할 것인지 아니면 다시 계산할 것인지 결정해야 함

* 역전파를 수행하는 데 필요한 계산량은 순전파 계산 그래프드의 간선 개수에 선형으로 비례하며, 그래프의 각 간선은 하나의 노드의 편미분 계산과 곱하기 1회 및 더하기 1회를 수행한다.

## 완전 연결 MLP의 역전파 계산

![순전파 알고리즘](https://i.stack.imgur.com/NSWW1.png)

![역전파 알고리즘](https://i.stack.imgur.com/dd4aH.png)

* 위 알고리즘은 특정한 문제 하나에만 특화된 형태임
* 현대의 알고리즘은 보다 일반화된 형태의 역전파 알고리즘에 기초하고 있음
