# 4-3. 기울기 벡터 기반 최적화

* 최적화(optimization): x의 값을 바꾸어 가면서 어떤 함수 f(x)의 값을 최대화 또는 최소화하는 것
* 목적함수(objective function): 최소화 또는 최대화할 함수
    * 최소화의 경우엔 비용함수, 손실함수, 오차함수라고 부름
* 함수를 최소화 또는 최대화하는 인수의 값에 흔히 위 첨자 <sup>\*</sup>를 붙인다. x<sup>\*</sup>는 argminf(x)이다.

## 경사 하강법

* 경사 하강법(gradient descent): x를 미분과는 부호가 반대인 방향으로 이동함으로써 f(x)의 값을 줄이는 방법
    * 임계점(critical point): f(x)의 도함수가 0인 점
    * 극소점(local minimum point): f(x)가 모든 이웃 점보다 작은 점
    * 안장점(saddle point): 극소점, 극대점이 아닌 임계점
    * 전역 최소점(global minimum): f(x)가 가장 작은 값이 되는 점

* 편미분: 점 x에서 변수 x<sub>i</sub>만 증가했을 때의 f의 변화를 측정
* 기울기(gradient, 그래디언트): 미분의 개념을 입력이 여러 개인 함수로 일반화한 것
* 학습 속도(learning rate): 이동 단계의 크기